import { GoogleGenAI, FunctionDeclaration, Type, Tool, Content, Part } from "@google/genai";
import { Message, TeamMember } from "../types";
import { DEFAULT_TEAM } from "../constants";

// LISTA DE MODELOS (ORDEM DE PRIORIDADE)
const MODEL_CANDIDATES = [
  'gemini-1.5-flash',          
  'gemini-1.5-flash-latest',   
  'gemini-2.0-flash-exp',
  'gemini-1.5-pro'      
];

const cleanKey = (key: string | undefined): string => {
  if (!key) return '';
  return key.replace(/["'\s\n\r]/g, '').trim();
};

const shuffleArray = (array: string[]) => {
  const newArr = [...array];
  for (let i = newArr.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [newArr[i], newArr[j]] = [newArr[j], newArr[i]];
  }
  return newArr;
};

export const getAvailableApiKeysMap = (): Record<string, string> => {
  const keysMap: Record<string, string> = {};

  const explicitKeys = [
    { name: 'API_KEY_1', val: process.env.API_KEY_1 },
    { name: 'API_KEY_2', val: process.env.API_KEY_2 },
    { name: 'API_KEY_3', val: process.env.API_KEY_3 },
    { name: 'API_KEY_4', val: process.env.API_KEY_4 },
    { name: 'API_KEY_5', val: process.env.API_KEY_5 },
    { name: 'API_KEY_6', val: process.env.API_KEY_6 },
  ];

  explicitKeys.forEach(k => {
    if (k.val && k.val.length > 10) keysMap[k.name] = k.val;
  });

  const envSources = [
    typeof process !== 'undefined' ? process.env : {},
    (import.meta as any).env || {}
  ];

  envSources.forEach(source => {
    if (!source) return;
    Object.entries(source).forEach(([key, val]) => {
      if (keysMap[key]) return;
      if (typeof val === 'string' && val.startsWith('AIza') && val.length > 20) {
        keysMap[key] = val;
      }
    });
  });

  const localKey = localStorage.getItem('mara_gemini_api_key');
  if (localKey) keysMap['LOCAL_STORAGE'] = localKey;

  return keysMap;
};

export const getAvailableApiKeys = (): string[] => {
  const map = getAvailableApiKeysMap();
  return [...new Set(Object.values(map))].map(cleanKey);
};

const notifyTeamFunction: FunctionDeclaration = {
  name: 'notificar_equipe',
  description: 'Notifica o advogado respons√°vel com o relat√≥rio completo.',
  parameters: {
    type: Type.OBJECT,
    properties: {
      clientName: { type: Type.STRING },
      summary: { type: Type.STRING },
      lawyerName: { type: Type.STRING },
      priority: { type: Type.STRING }
    },
    required: ['clientName', 'summary', 'lawyerName', 'priority'],
  },
};

const tools: Tool[] = [{ functionDeclarations: [notifyTeamFunction] }];

// --- IA NATIVA 4.0 (FLUXO NATURAL & CONTEXTUAL) ---
const runNativeMara = async (
  history: Message[], 
  lastUserText: string,
  onToolCall?: (toolCall: any) => void,
  caseContext?: string
): Promise<string> => {
  console.log("[Mara Native] Analisando inten√ß√£o natural...");
  
  // 1. Resposta sobre Prontu√°rio (Contexto Priorit√°rio)
  if (caseContext && lastUserText.toLowerCase().match(/(como est√°|andamento|novidades|processo|per√≠cia|audi√™ncia|status)/)) {
     return `Verifiquei aqui no sistema sobre o seu caso:\n\n"${caseContext}"\n\nQualquer outra d√∫vida sobre isso, pode me perguntar.`;
  }
  
  const lower = lastUserText.toLowerCase().trim();
  const lastBotMsg = [...history].reverse().find(m => m.role === 'model')?.content || "";
  
  // 2. Detec√ß√£o de Intent e Sentimento Simples
  // Se for apenas sauda√ß√£o, seja receptiva
  if (history.length < 3 || ['oi', 'ol√°', 'bom dia', 'tarde', 'noite', 'tudo bem'].some(x => lower === x || lower.startsWith(x + ' '))) {
    return "Ol√°! Aqui √© a Mara. ‚öñÔ∏è\n\nEstou pronta para te ouvir. Pode me contar o que aconteceu ou qual sua d√∫vida hoje?";
  }

  // 3. L√≥gica Contextual (Simulada sem LLM)
  
  // --- INSS ---
  if (lower.match(/(inss|aposenta|benef√≠cio|loas|doen√ßa|encostado|per√≠cia|aux√≠lio)/)) {
      if (lower.includes("negado") || lower.includes("cortaram")) {
          return "Poxa, ter o benef√≠cio negado √© muito frustrante. üòü Mas podemos reverter.\n\nVoc√™ tem os laudos m√©dicos atuais e a carta de indeferimento do INSS?";
      }
      return "Entendo, quest√µes com o INSS exigem cuidado. \n\nPara o Dr. Michel analisar, me diga: Qual a sua idade hoje e h√° quanto tempo voc√™ contribui?";
  }

  // --- TRABALHISTA ---
  if (lower.match(/(trabalh|empresa|patr√£o|demi|verba|justa causa|fgts|carteira|sal√°rio)/)) {
      if (lower.includes("n√£o pagou") || lower.includes("atrasado")) {
          return "Isso √© grave. O sal√°rio √© sagrado. \n\nEsse atraso acontece h√° muito tempo? Sua carteira √© assinada?";
      }
      if (lower.includes("demiti") || lower.includes("mandou embora")) {
         return "Sinto muito por isso. Perder o emprego √© dif√≠cil. \n\nVoc√™ sabe se eles v√£o pagar todos os seus direitos na rescis√£o? Voc√™ tinha carteira assinada?";
      }
      return "Certo, assunto trabalhista. \n\nPara eu passar para a Dra. Luana: Voc√™ ainda est√° trabalhando l√° ou j√° saiu?";
  }

  // --- FAM√çLIA ---
  if (lower.match(/(fam√≠lia|div√≥rcio|separa√ß√£o|pens√£o|guarda|invent√°rio|heran√ßa|ex-marido|ex-mulher)/)) {
      if (lower.includes("n√£o paga") && lower.includes("pens√£o")) {
          return "Entendo perfeitamente sua preocupa√ß√£o. A pens√£o √© direito da crian√ßa. \n\nJ√° existe um valor fixado pelo juiz ou era apenas um acordo de boca?";
      }
      return "Compreendo. Assuntos de fam√≠lia mexem com a gente. \n\nPara a Dra. Fl√°via te orientar melhor: Existem filhos menores de idade envolvidos nesse caso?";
  }

  // Continuidade de conversa (Mem√≥ria Curta Simulada)
  if (lastBotMsg.includes("idade") && lower.match(/\d+/)) {
      return "Certo. E voc√™ tem acesso √† senha do site 'Meu INSS' (Gov.br)? Isso ajuda muito na an√°lise do Dr. Michel.";
  }
  if (lastBotMsg.includes("carteira") && (lower.includes("sim") || lower.includes("n√£o"))) {
      if (onToolCall) performHandover(history, lastUserText, "Dra. Luana Castro", onToolCall);
      return "Entendido. A falta de registro ou pagamento errado gera muitos direitos. \n\nJ√° passei seu relato para a Dra. Luana. Vamos analisar se cabe uma a√ß√£o urgente. A Fabr√≠cia vai entrar em contato para agendar.";
  }

  // Fallback gen√©rico, mas educado
  return "Entendi. Pode me dar mais alguns detalhes sobre isso? Quanto mais voc√™ me contar, melhor consigo explicar para o advogado respons√°vel.";
};

// Helper para finalizar o atendimento no modo nativo
const performHandover = (history: Message[], lastText: string, lawyer: string, onToolCall: (t: any) => void) => {
  const fullSummary = history.filter(m => m.role === 'user').map(m => m.content).join(" | ") + " | " + lastText;
  onToolCall({
    name: 'notificar_equipe',
    args: {
      clientName: 'Cliente (Triagem Natural)',
      summary: `TRIAGEM AUTOM√ÅTICA:\n${fullSummary}`,
      lawyerName: lawyer,
      priority: 'Alta'
    }
  });
};

export const testConnection = async (): Promise<{ success: boolean; message: string; keyUsed?: string }> => {
  const keys = getAvailableApiKeys();
  if (keys.length === 0) return { success: false, message: "Nenhuma chave encontrada." };

  for (const apiKey of keys) {
    const ai = new GoogleGenAI({ apiKey });
    try {
      const chat = ai.chats.create({ model: 'gemini-1.5-flash', history: [] });
      await chat.sendMessage({ message: "Ping" });
      return { success: true, message: "Conectado!", keyUsed: apiKey.slice(-4) };
    } catch (e:any) {}
  }
  return { success: false, message: "Falha na conex√£o API." };
};

export const sendMessageToGemini = async (
  history: Message[],
  newMessage: { text?: string; audioBase64?: string; mimeType?: string },
  systemInstruction: string,
  onToolCall?: (toolCall: any) => void,
  caseContext?: string // NOVO PARAMETRO
): Promise<string> => {
  
  let apiKeys = getAvailableApiKeys();
  
  if (apiKeys.length === 0) {
    return runNativeMara(history, newMessage.text || "", onToolCall, caseContext);
  }

  apiKeys = shuffleArray(apiKeys);
  const modelsToTry = MODEL_CANDIDATES;
  const recentHistory = history.slice(-10); 
  
  // INJE√á√ÉO DIN√ÇMICA DE CONTEXTO
  let dynamicPrompt = systemInstruction;
  
  // 1. Injeta Equipe
  try {
     const savedTeam = localStorage.getItem('mara_team_config');
     const team: TeamMember[] = savedTeam ? JSON.parse(savedTeam) : DEFAULT_TEAM;
     const teamList = team.map(t => `- ${t.name} (${t.role})`).join('\n');
     dynamicPrompt += `\n\n### üë• EQUIPE ATUAL DO ESCRIT√ìRIO:\n${teamList}\nUse estes nomes para direcionar o cliente.`;
  } catch(e) {}

  // 2. Injeta Status do Caso (Prontu√°rio)
  if (caseContext && caseContext.length > 5) {
     dynamicPrompt += `\n\n### üìÇ PRONTU√ÅRIO/STATUS ATUAL DO CLIENTE (MUITO IMPORTANTE):\nO advogado deixou a seguinte nota sobre o andamento deste caso:\n"${caseContext}"\n\nSE O CLIENTE PERGUNTAR SOBRE ANDAMENTO, DATA DE PER√çCIA OU STATUS, USE ESTA INFORMA√á√ÉO PARA RESPONDER. SEJA CLARO E TRANQUILIZE O CLIENTE.`;
  }

  const chatHistory: Content[] = recentHistory
    .filter(m => m.role !== 'system' && !m.content.includes('‚ö†Ô∏è'))
    .map(m => ({
      role: m.role,
      parts: [{ text: m.type === 'audio' ? '(√Åudio do usu√°rio)' : m.content }]
    }));

  const currentParts: Part[] = [];
  if (newMessage.audioBase64) {
    currentParts.push({
      inlineData: {
        mimeType: newMessage.mimeType || 'audio/webm;codecs=opus',
        data: newMessage.audioBase64
      }
    });
  }
  const textToSend = newMessage.text || "(√Åudio)";
  if (newMessage.text) currentParts.push({ text: newMessage.text });

  // MODO 2: Tenta API do Google
  for (const apiKey of apiKeys) {
    const ai = new GoogleGenAI({ apiKey });

    for (const model of modelsToTry) {
        try {
            const chat = ai.chats.create({
                model: model,
                config: { 
                  systemInstruction: dynamicPrompt,
                  tools, 
                  thinkingConfig: { thinkingBudget: 0 } 
                },
                history: chatHistory
            });

            const timeoutPromise = new Promise((_, reject) => setTimeout(() => reject(new Error("Timeout")), 12000));
            const apiPromise = chat.sendMessage({ message: currentParts });

            const result: any = await Promise.race([apiPromise, timeoutPromise]);
            
            let responseText = result.text || "";

            if (result.functionCalls && result.functionCalls.length > 0) {
                const call = result.functionCalls[0];
                if (onToolCall) onToolCall({ name: call.name, args: call.args });
                const fnResp = await chat.sendMessage({
                  message: [{ functionResponse: { name: call.name, response: { result: "OK" } } }]
                });
                responseText = fnResp.text || "";
            }
            
            return responseText;

        } catch (error: any) {
            const isQuota = error.message?.includes('429') || error.message?.includes('Quota');
            if (isQuota) break; 
        }
    }
  }

  return runNativeMara(history, textToSend, onToolCall, caseContext);
};