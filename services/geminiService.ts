import { GoogleGenAI, FunctionDeclaration, Type, Tool, Content, Part } from "@google/genai";
import { Message, TeamMember } from "../types";
import { DEFAULT_TEAM } from "../constants";

// LISTA DE MODELOS (ORDEM DE PRIORIDADE)
const MODEL_CANDIDATES = [
  'gemini-1.5-flash',          
  'gemini-1.5-flash-latest',   
  'gemini-2.0-flash-exp',
  'gemini-1.5-pro'      
];

const cleanKey = (key: string | undefined): string => {
  if (!key) return '';
  return key.replace(/["'\s\n\r]/g, '').trim();
};

const shuffleArray = (array: string[]) => {
  const newArr = [...array];
  for (let i = newArr.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [newArr[i], newArr[j]] = [newArr[j], newArr[i]];
  }
  return newArr;
};

export const getAvailableApiKeysMap = (): Record<string, string> => {
  const keysMap: Record<string, string> = {};

  const explicitKeys = [
    { name: 'API_KEY_1', val: process.env.API_KEY_1 },
    { name: 'API_KEY_2', val: process.env.API_KEY_2 },
    { name: 'API_KEY_3', val: process.env.API_KEY_3 },
    { name: 'API_KEY_4', val: process.env.API_KEY_4 },
    { name: 'API_KEY_5', val: process.env.API_KEY_5 },
    { name: 'API_KEY_6', val: process.env.API_KEY_6 },
  ];

  explicitKeys.forEach(k => {
    if (k.val && k.val.length > 10) keysMap[k.name] = k.val;
  });

  const envSources = [
    typeof process !== 'undefined' ? process.env : {},
    (import.meta as any).env || {}
  ];

  envSources.forEach(source => {
    if (!source) return;
    Object.entries(source).forEach(([key, val]) => {
      if (keysMap[key]) return;
      if (typeof val === 'string' && val.startsWith('AIza') && val.length > 20) {
        keysMap[key] = val;
      }
    });
  });

  const localKey = localStorage.getItem('mara_gemini_api_key');
  if (localKey) keysMap['LOCAL_STORAGE'] = localKey;

  return keysMap;
};

export const getAvailableApiKeys = (): string[] => {
  const map = getAvailableApiKeysMap();
  return [...new Set(Object.values(map))].map(cleanKey);
};

const notifyTeamFunction: FunctionDeclaration = {
  name: 'notificar_equipe',
  description: 'Notifica o advogado respons√°vel com o relat√≥rio completo.',
  parameters: {
    type: Type.OBJECT,
    properties: {
      clientName: { type: Type.STRING },
      summary: { type: Type.STRING },
      lawyerName: { type: Type.STRING },
      priority: { type: Type.STRING }
    },
    required: ['clientName', 'summary', 'lawyerName', 'priority'],
  },
};

const tools: Tool[] = [{ functionDeclarations: [notifyTeamFunction] }];

// --- IA NATIVA 4.0 (L√ìGICA CONSULTIVA & FLUIDA) ---
// Essa fun√ß√£o roda quando a API do Google falha, garantindo que a Mara n√£o fique "burra".
const runNativeMara = async (
  history: Message[], 
  lastUserText: string,
  onToolCall?: (toolCall: any) => void,
  caseContext?: string
): Promise<string> => {
  console.log("[Mara Native] Modo Consultivo Ativado...");
  
  const lower = lastUserText.toLowerCase().trim();
  const cleanText = lower.replace(/[!?.s]/g, ' ').trim(); 
  
  // Recupera a √∫ltima coisa que a MARA disse para manter o contexto
  const lastBotMsgRaw = [...history].reverse().find(m => m.role === 'model')?.content || "";
  const lastBotMsg = lastBotMsgRaw.toLowerCase();

  // 1. PRIORIDADE: CONTEXTO DO CASO (PRONTU√ÅRIO)
  if (caseContext && lower.match(/(como est√°|andamento|novidades|processo|per√≠cia|audi√™ncia|status|not√≠cias)/)) {
     return `Oi! Consultei aqui o sistema rapidinho. \n\n${caseContext}\n\nFique tranquilo, qualquer novidade extra te avisamos!`;
  }

  // 2. DETEC√á√ÉO DE PERGUNTA DO USU√ÅRIO (EVITA O LOOP "QUE DETALHES?")
  if (lower.includes('que detalhes') || lower.includes('quais detalhes') || lower.includes('como assim') || lower.includes('o que falar')) {
    return "Ah, desculpe! üòÖ Eu preciso saber um pouco sobre o que aconteceu para chamar o advogado certo.\n\nPor exemplo: √© sobre demiss√£o no trabalho? Benef√≠cio do INSS negado? Ou pens√£o aliment√≠cia?";
  }

  // 3. SAUDA√á√ïES (Respondendo com educa√ß√£o)
  if (/(oi|ola|ol√°|bom dia|boa tarde|boa noite|tudo bem|ei|opa)\b/.test(lower) && history.length < 3) {
    return "Ol√°! Tudo bem? Sou a Mara, assistente virtual da Felix e Castro. üëã\n\nPode me contar o que houve? Estou aqui para te ouvir.";
  }

  // 4. L√ìGICA DE CONTEXTO (Respondendo perguntas anteriores)
  
  // Se a Mara perguntou idade antes...
  if (lastBotMsg.includes('idade') || lastBotMsg.includes('anos')) {
    if (lower.match(/\d+/)) {
       return "Certo, anotei sua idade. E voc√™ sabe me dizer quanto tempo de contribui√ß√£o (registro) voc√™ tem mais ou menos?";
    }
  }

  // Se a Mara perguntou se trabalha ou saiu...
  if ((lastBotMsg.includes('trabalhando') || lastBotMsg.includes('saiu')) && (lower.includes('sai') || lower.includes('trabalho') || lower.includes('ainda'))) {
     return "Entendi. E sua carteira de trabalho foi assinada direitinho ou n√£o registraram?";
  }

  // 5. DETEC√á√ÉO DE √ÅREA (INTENT RECOGNITION)

  // --- INSS ---
  if (lower.match(/(inss|aposenta|benef√≠cio|loas|doen√ßa|encostado|per√≠cia|aux√≠lio|bpc|deficiente)/)) {
      return "Entendi, √© uma quest√£o previdenci√°ria. O Dr. Michel √© especialista nisso. \n\nVoc√™ j√° deu entrada no pedido e foi negado, ou quer dar entrada agora?";
  }

  // --- TRABALHISTA ---
  if (lower.match(/(trabalh|empresa|patr√£o|demi|verba|justa causa|fgts|carteira|sal√°rio|acerto|rescis√£o)/)) {
      return "Compreendo, parece ser um caso trabalhista para a Dra. Luana. \n\nMe diga uma coisa: voc√™ ainda est√° trabalhando na empresa ou j√° saiu?";
  }

  // --- FAM√çLIA ---
  if (lower.match(/(fam√≠lia|div√≥rcio|separa√ß√£o|pens√£o|guarda|invent√°rio|heran√ßa|ex-marido|ex-mulher|visita)/)) {
      return "Certo, assuntos de fam√≠lia precisam de aten√ß√£o especial da Dra. Fl√°via. \n\nNesse caso, existem filhos menores de idade envolvidos?";
  }

  // 6. ENCERRAMENTO DE TRIAGEM (HANDOVER)
  // Se o usu√°rio j√° falou bastante (heur√≠stica simples)
  if (history.length > 6) {
      if (onToolCall) {
        const fullSummary = history.filter(m => m.role === 'user').map(m => m.content).join(" | ");
        onToolCall({
          name: 'notificar_equipe',
          args: {
            clientName: 'Cliente (Via Chat)',
            summary: fullSummary,
            lawyerName: 'A Definir na Triagem',
            priority: 'M√©dia'
          }
        });
      }
      return "Obrigada pelas informa√ß√µes! üôè\n\nJ√° passei tudo para a nossa equipe. Como seu caso tem detalhes importantes, vou pedir para a secret√°ria analisar a agenda dos advogados e entrar em contato com voc√™ ainda hoje.";
  }

  // 7. FALLBACK INTELIGENTE (QUANDO N√ÉO ENTENDE)
  // Em vez de "N√£o entendi", ela oferece op√ß√µes.
  return "Entendi que voc√™ precisa de ajuda jur√≠dica. \n\nPara eu chamar o especialista certo, me fale s√≥ mais uma coisa: \nIsso √© sobre algum problema no **Trabalho**, com o **INSS** ou quest√£o de **Fam√≠lia**?";
};

export const testConnection = async (): Promise<{ success: boolean; message: string; keyUsed?: string }> => {
  const keys = getAvailableApiKeys();
  if (keys.length === 0) return { success: false, message: "Nenhuma chave encontrada." };

  for (const apiKey of keys) {
    const ai = new GoogleGenAI({ apiKey });
    try {
      const chat = ai.chats.create({ model: 'gemini-1.5-flash', history: [] });
      await chat.sendMessage({ message: "Ping" });
      return { success: true, message: "Conectado!", keyUsed: apiKey.slice(-4) };
    } catch (e:any) {}
  }
  return { success: false, message: "Falha na conex√£o API." };
};

export const sendMessageToGemini = async (
  history: Message[],
  newMessage: { text?: string; audioBase64?: string; mimeType?: string },
  systemInstruction: string,
  onToolCall?: (toolCall: any) => void,
  caseContext?: string // NOVO PARAMETRO
): Promise<string> => {
  
  let apiKeys = getAvailableApiKeys();
  
  if (apiKeys.length === 0) {
    return runNativeMara(history, newMessage.text || "", onToolCall, caseContext);
  }

  apiKeys = shuffleArray(apiKeys);
  const modelsToTry = MODEL_CANDIDATES;
  const recentHistory = history.slice(-10); 
  
  // INJE√á√ÉO DIN√ÇMICA DE CONTEXTO
  let dynamicPrompt = systemInstruction;
  
  // 1. Injeta Equipe
  try {
     const savedTeam = localStorage.getItem('mara_team_config');
     const team: TeamMember[] = savedTeam ? JSON.parse(savedTeam) : DEFAULT_TEAM;
     const teamList = team.map(t => `- ${t.name} (${t.role})`).join('\n');
     dynamicPrompt += `\n\n### üë• EQUIPE ATUAL DO ESCRIT√ìRIO:\n${teamList}\nUse estes nomes para direcionar o cliente.`;
  } catch(e) {}

  // 2. Injeta Status do Caso (Prontu√°rio)
  if (caseContext && caseContext.length > 5) {
     dynamicPrompt += `\n\n### üìÇ PRONTU√ÅRIO/STATUS ATUAL DO CLIENTE (MUITO IMPORTANTE):\nO advogado deixou a seguinte nota sobre o andamento deste caso:\n"${caseContext}"\n\nSE O CLIENTE PERGUNTAR SOBRE ANDAMENTO, DATA DE PER√çCIA OU STATUS, USE ESTA INFORMA√á√ÉO PARA RESPONDER. SEJA CLARO E TRANQUILIZE O CLIENTE.`;
  }

  const chatHistory: Content[] = recentHistory
    .filter(m => m.role !== 'system' && !m.content.includes('‚ö†Ô∏è'))
    .map(m => ({
      role: m.role,
      parts: [{ text: m.type === 'audio' ? '(√Åudio do usu√°rio)' : m.content }]
    }));

  const currentParts: Part[] = [];
  if (newMessage.audioBase64) {
    currentParts.push({
      inlineData: {
        mimeType: newMessage.mimeType || 'audio/webm;codecs=opus',
        data: newMessage.audioBase64
      }
    });
  }
  const textToSend = newMessage.text || "(√Åudio)";
  if (newMessage.text) currentParts.push({ text: newMessage.text });

  // MODO 2: Tenta API do Google
  for (const apiKey of apiKeys) {
    const ai = new GoogleGenAI({ apiKey });

    for (const model of modelsToTry) {
        try {
            const chat = ai.chats.create({
                model: model,
                config: { 
                  systemInstruction: dynamicPrompt,
                  tools, 
                  thinkingConfig: { thinkingBudget: 0 } 
                },
                history: chatHistory
            });

            const timeoutPromise = new Promise((_, reject) => setTimeout(() => reject(new Error("Timeout")), 12000));
            const apiPromise = chat.sendMessage({ message: currentParts });

            const result: any = await Promise.race([apiPromise, timeoutPromise]);
            
            let responseText = result.text || "";

            if (result.functionCalls && result.functionCalls.length > 0) {
                const call = result.functionCalls[0];
                if (onToolCall) onToolCall({ name: call.name, args: call.args });
                const fnResp = await chat.sendMessage({
                  message: [{ functionResponse: { name: call.name, response: { result: "OK" } } }]
                });
                responseText = fnResp.text || "";
            }
            
            return responseText;

        } catch (error: any) {
            const isQuota = error.message?.includes('429') || error.message?.includes('Quota');
            if (isQuota) break; 
        }
    }
  }

  return runNativeMara(history, textToSend, onToolCall, caseContext);
};